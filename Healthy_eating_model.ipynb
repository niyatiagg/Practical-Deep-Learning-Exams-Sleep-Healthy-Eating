{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHS+kuGYjSPSW9OrQC9zq7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRaLP9-vMqfV"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Untitled6.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Rllywmf7_wZO-d5BH4TSvDNrbB2W9qJX\n",
        "\"\"\"\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Healthy Eating Classification Model\n",
        "Analyzes nutritional data to predict if food items are healthy\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
        "                          roc_curve, precision_recall_curve, auc, f1_score,\n",
        "                          precision_score, recall_score, accuracy_score)\n",
        "from sklearn.inspection import permutation_importance, partial_dependence\n",
        "from sklearn.metrics import accuracy_score\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    SMOTE_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SMOTE_AVAILABLE = False\n",
        "    print(\"Warning: imbalanced-learn not installed. SMOTE will not be used.\")\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "class HealthyEatingClassifier:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_columns = None\n",
        "        self.target_thresholds = {\n",
        "            'calories_per_100g': 300,  # High calorie threshold\n",
        "            'saturated_fat_per_100g': 5,  # High saturated fat threshold\n",
        "            'sugar_per_100g': 15,  # High sugar threshold\n",
        "            'sodium_per_100g': 400  # High sodium threshold (mg)\n",
        "        }\n",
        "\n",
        "    def load_and_explore_data(self, file_path):\n",
        "        \"\"\"Load and perform exploratory data analysis\"\"\"\n",
        "        print(\"Loading Healthy Eating Dataset...\")\n",
        "        self.df = pd.read_csv(file_path)\n",
        "\n",
        "        print(f\"Dataset shape: {self.df.shape}\")\n",
        "        print(f\"\\nColumn names in dataset:\")\n",
        "        print(list(self.df.columns))\n",
        "\n",
        "        print(\"\\nDataset Info:\")\n",
        "        print(self.df.info())\n",
        "        print(\"\\nFirst few rows:\")\n",
        "        print(self.df.head())\n",
        "        print(\"\\nDataset Statistics:\")\n",
        "        print(self.df.describe())\n",
        "\n",
        "        # Check for missing values\n",
        "        print(\"\\nMissing values:\")\n",
        "        missing_summary = self.df.isnull().sum()\n",
        "        print(missing_summary[missing_summary > 0] if (missing_summary > 0).any() else \"No missing values\")\n",
        "\n",
        "        # Check which nutrient columns exist\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"NUTRIENT COLUMN CHECK\")\n",
        "        print(f\"{'='*80}\")\n",
        "        expected_nutrients = ['calories', 'protein', 'carbs', 'fat', 'fiber', 'sugar', 'sodium', 'saturated_fat']\n",
        "        expected_per_100g = [f'{n}_per_100g' for n in expected_nutrients]\n",
        "\n",
        "        print(\"\\nExpected base nutrients:\")\n",
        "        for nutrient in expected_nutrients:\n",
        "            exists = \"✓\" if nutrient in self.df.columns else \"✗\"\n",
        "            print(f\"  {exists} {nutrient}\")\n",
        "\n",
        "        print(\"\\nExpected per_100g columns:\")\n",
        "        for nutrient in expected_per_100g:\n",
        "            exists = \"✓\" if nutrient in self.df.columns else \"✗\"\n",
        "            print(f\"  {exists} {nutrient}\")\n",
        "\n",
        "        # Check if serving_size_g exists\n",
        "        if 'serving_size_g' in self.df.columns:\n",
        "            print(f\"\\n✓ serving_size_g found\")\n",
        "            print(f\"  Mean: {self.df['serving_size_g'].mean():.2f}g\")\n",
        "            print(f\"  Min: {self.df['serving_size_g'].min():.2f}g\")\n",
        "            print(f\"  Max: {self.df['serving_size_g'].max():.2f}g\")\n",
        "        else:\n",
        "            print(f\"\\n✗ serving_size_g NOT found - assuming data is already per 100g\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def create_healthy_target(self):\n",
        "        \"\"\"Create or verify is_healthy target variable\"\"\"\n",
        "        print(\"Checking healthy eating target variable...\")\n",
        "\n",
        "        # Check if target already exists in dataset\n",
        "        if 'is_healthy' in self.df.columns:\n",
        "            print(\"✓ Target variable 'is_healthy' already exists in dataset - using it directly!\")\n",
        "            print(\"  (Not creating new target from thresholds)\")\n",
        "        else:\n",
        "            print(\"Creating new target variable from nutritional thresholds...\")\n",
        "\n",
        "            # Verify required columns exist\n",
        "            required_cols = ['calories_per_100g', 'saturated_fat_per_100g', 'sugar_per_100g', 'sodium_per_100g']\n",
        "            missing = [col for col in required_cols if col not in self.df.columns]\n",
        "            if missing:\n",
        "                print(f\"ERROR: Missing required columns: {missing}\")\n",
        "                print(f\"Available columns: {list(self.df.columns)}\")\n",
        "                raise KeyError(f\"Missing required columns for target creation: {missing}\")\n",
        "\n",
        "            # Define healthy criteria (lower is better for these nutrients)\n",
        "            healthy_criteria = (\n",
        "                (self.df['calories_per_100g'] <= self.target_thresholds['calories_per_100g']) &\n",
        "                (self.df['saturated_fat_per_100g'] <= self.target_thresholds['saturated_fat_per_100g']) &\n",
        "                (self.df['sugar_per_100g'] <= self.target_thresholds['sugar_per_100g']) &\n",
        "                (self.df['sodium_per_100g'] <= self.target_thresholds['sodium_per_100g'])\n",
        "            )\n",
        "\n",
        "            self.df['is_healthy'] = healthy_criteria.astype(int)\n",
        "\n",
        "        print(f\"\\nTarget Distribution:\")\n",
        "        print(f\"  Healthy food items: {self.df['is_healthy'].sum()}\")\n",
        "        print(f\"  Unhealthy food items: {(~self.df['is_healthy'].astype(bool)).sum()}\")\n",
        "        print(f\"  Healthy percentage: {self.df['is_healthy'].mean():.2%}\")\n",
        "\n",
        "        # Show sample of each class to verify target makes sense\n",
        "        if 'meal_name' in self.df.columns:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\"SAMPLE UNHEALTHY FOODS (first 3):\")\n",
        "            print(f\"{'='*80}\")\n",
        "            display_cols = ['meal_name', 'calories_per_100g', 'protein_per_100g', 'carbs_per_100g', 'fat_per_100g']\n",
        "            available_cols = [c for c in display_cols if c in self.df.columns]\n",
        "            unhealthy_samples = self.df[self.df['is_healthy'] == 0][available_cols].head(3)\n",
        "            print(unhealthy_samples.to_string())\n",
        "\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\"SAMPLE HEALTHY FOODS (first 3):\")\n",
        "            print(f\"{'='*80}\")\n",
        "            healthy_samples = self.df[self.df['is_healthy'] == 1][available_cols].head(3)\n",
        "            print(healthy_samples.to_string())\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def normalize_units(self):\n",
        "        \"\"\"Ensure all nutrients are per 100g consistently\"\"\"\n",
        "        print(\"Normalizing units to per 100g...\")\n",
        "\n",
        "        # Map YOUR dataset's column names to expected format\n",
        "        column_mapping = {\n",
        "            'protein_g': 'protein',\n",
        "            'carbs_g': 'carbs',\n",
        "            'fat_g': 'fat',\n",
        "            'fiber_g': 'fiber',\n",
        "            'sugar_g': 'sugar',\n",
        "            'sodium_mg': 'sodium',\n",
        "            # Note: Your dataset doesn't have saturated_fat, we'll handle this below\n",
        "        }\n",
        "\n",
        "        # Rename columns if they exist\n",
        "        for old_name, new_name in column_mapping.items():\n",
        "            if old_name in self.df.columns:\n",
        "                self.df[new_name] = self.df[old_name]\n",
        "                print(f\"  Mapped {old_name} → {new_name}\")\n",
        "\n",
        "        nutrient_cols = ['calories', 'protein', 'carbs', 'fat', 'fiber', 'sugar', 'sodium', 'saturated_fat']\n",
        "\n",
        "        # First, check if *_per_100g columns already exist in the dataset\n",
        "        per_100g_exists = any(f'{col}_per_100g' in self.df.columns for col in nutrient_cols)\n",
        "\n",
        "        if per_100g_exists:\n",
        "            # Dataset already has per_100g columns - just ensure all exist\n",
        "            print(\"Dataset already contains per_100g columns\")\n",
        "            for col in nutrient_cols:\n",
        "                per_col = f'{col}_per_100g'\n",
        "                if per_col not in self.df.columns:\n",
        "                    # Try to find the base column\n",
        "                    if col in self.df.columns:\n",
        "                        self.df[per_col] = self.df[col].fillna(0)\n",
        "                    else:\n",
        "                        print(f\"Warning: Missing both {col} and {per_col}, creating with zeros\")\n",
        "                        self.df[per_col] = 0.0\n",
        "                else:\n",
        "                    # Fill any NaNs in existing per_100g columns\n",
        "                    self.df[per_col] = self.df[per_col].fillna(0)\n",
        "\n",
        "        elif 'serving_size_g' in self.df.columns:\n",
        "            # Has serving size, need to normalize\n",
        "            print(\"Normalizing from serving size to per 100g\")\n",
        "            serving = self.df['serving_size_g'].replace(0, np.nan)\n",
        "\n",
        "            for col in nutrient_cols:\n",
        "                per_col = f'{col}_per_100g'\n",
        "                if col in self.df.columns:\n",
        "                    # For sodium, convert mg to mg (already correct unit)\n",
        "                    self.df[per_col] = (self.df[col] / serving * 100).fillna(0)\n",
        "                    print(f\"  Created {per_col} from {col}\")\n",
        "                else:\n",
        "                    # Column doesn't exist - check if it's saturated_fat\n",
        "                    if col == 'saturated_fat':\n",
        "                        print(f\"  Warning: {col} not in dataset, setting to 0\")\n",
        "                        self.df[per_col] = 0.0\n",
        "                    else:\n",
        "                        print(f\"  ERROR: {col} not found in dataset!\")\n",
        "                        self.df[per_col] = 0.0\n",
        "\n",
        "        else:\n",
        "            # No per_100g columns and no serving_size - assume raw columns are per 100g\n",
        "            print(\"Assuming raw columns are per 100g\")\n",
        "            for col in nutrient_cols:\n",
        "                per_col = f'{col}_per_100g'\n",
        "                if col in self.df.columns:\n",
        "                    self.df[per_col] = self.df[col].fillna(0)\n",
        "                else:\n",
        "                    print(f\"Warning: Missing {col}, creating {per_col} with zeros\")\n",
        "                    self.df[per_col] = 0.0\n",
        "\n",
        "        # Verify all required columns exist\n",
        "        missing_cols = [f'{col}_per_100g' for col in nutrient_cols if f'{col}_per_100g' not in self.df.columns]\n",
        "        if missing_cols:\n",
        "            print(f\"ERROR: Still missing columns after normalization: {missing_cols}\")\n",
        "            raise ValueError(f\"Failed to create required columns: {missing_cols}\")\n",
        "\n",
        "        # Show summary of created columns with sample values\n",
        "        print(\"\\nUnit normalization complete - Summary:\")\n",
        "        for col in nutrient_cols:\n",
        "            per_col = f'{col}_per_100g'\n",
        "            if per_col in self.df.columns:\n",
        "                non_zero = (self.df[per_col] != 0).sum()\n",
        "                mean_val = self.df[per_col].mean()\n",
        "                print(f\"  {per_col}: {non_zero}/{len(self.df)} non-zero, mean={mean_val:.2f}\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def engineer_features(self):\n",
        "        \"\"\"Create meaningful derived features WITHOUT leaking the target\"\"\"\n",
        "        print(\"Engineering features...\")\n",
        "\n",
        "        # Core nutrients (ensure they exist)\n",
        "        core_nutrients = ['calories_per_100g', 'protein_per_100g', 'carbs_per_100g',\n",
        "                         'fat_per_100g', 'fiber_per_100g', 'sugar_per_100g', 'sodium_per_100g', 'saturated_fat_per_100g']\n",
        "\n",
        "        # Add missing columns with zeros if they don't exist\n",
        "        for nutrient in core_nutrients:\n",
        "            if nutrient not in self.df.columns:\n",
        "                base_name = nutrient.replace('_per_100g', '')\n",
        "                if base_name in self.df.columns:\n",
        "                    self.df[nutrient] = self.df[base_name].fillna(0)\n",
        "                else:\n",
        "                    self.df[nutrient] = 0\n",
        "\n",
        "        # Safe derived features that don't directly leak\n",
        "        calories = self.df['calories_per_100g'].replace(0, 1)\n",
        "        protein = self.df['protein_per_100g']\n",
        "        carbs = self.df['carbs_per_100g']\n",
        "        fat = self.df['fat_per_100g']\n",
        "        fiber = self.df['fiber_per_100g'].replace(0, 1)\n",
        "        sugar = self.df['sugar_per_100g']\n",
        "        sodium = self.df['sodium_per_100g']\n",
        "        sat_fat = self.df['saturated_fat_per_100g']\n",
        "\n",
        "        # SAFE nutrient densities (only use non-leaking nutrients)\n",
        "        self.df['protein_density'] = protein / calories\n",
        "        self.df['fiber_density'] = fiber / calories\n",
        "        # DO NOT USE: sugar_density, sodium_density (leak the target thresholds)\n",
        "\n",
        "        # SAFE nutrient ratios (relationships between safe nutrients)\n",
        "        self.df['protein_to_fat_ratio'] = protein / fat.replace(0, 1)\n",
        "        self.df['protein_to_carb_ratio'] = protein / carbs.replace(0, 1)\n",
        "        self.df['fiber_to_carb_ratio'] = fiber / carbs.replace(0, 1)\n",
        "        # DO NOT USE: sat_fat_ratio (leaks saturated fat threshold)\n",
        "        self.df['carb_fiber_ratio'] = carbs / fiber\n",
        "        self.df['fat_to_carb_ratio'] = fat / carbs.replace(0, 1)\n",
        "\n",
        "        # Macronutrient balance features (SAFE - relative proportions)\n",
        "        total_macro = protein + carbs + fat\n",
        "        self.df['protein_pct'] = protein / total_macro.replace(0, 1)\n",
        "        self.df['carb_pct'] = carbs / total_macro.replace(0, 1)\n",
        "        self.df['fat_pct'] = fat / total_macro.replace(0, 1)\n",
        "\n",
        "        # SAFE quality indicators (only positive nutrients)\n",
        "        self.df['nutrient_density_score'] = (protein + fiber) / calories\n",
        "        self.df['protein_fiber_ratio'] = protein / fiber\n",
        "        # DO NOT USE: empty_calorie_ratio, sodium_to_protein_ratio (leak thresholds)\n",
        "\n",
        "        # SAFE interaction features (only non-leaking nutrients)\n",
        "        self.df['protein_fiber_product'] = protein * fiber\n",
        "        self.df['protein_carb_product'] = protein * carbs\n",
        "        # DO NOT USE: sugar_fat_product (leaks sugar threshold)\n",
        "\n",
        "        # Categorical features (one-hot encoding)\n",
        "        categorical_cols = ['cuisine', 'type', 'meal_category', 'ingredients']\n",
        "        for col in categorical_cols:\n",
        "            if col in self.df.columns:\n",
        "                # Limit to top categories to avoid too many features\n",
        "                top_categories = self.df[col].value_counts().head(10).index\n",
        "                for category in top_categories:\n",
        "                    self.df[f'{col}_{category}'] = (self.df[col] == category).astype(int)\n",
        "\n",
        "        print(f\"Total features after engineering: {self.df.shape[1]}\")\n",
        "        return self.df\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"Handle missing values and outliers\"\"\"\n",
        "        print(\"Cleaning data...\")\n",
        "\n",
        "        # Handle missing values\n",
        "        for col in self.df.columns:\n",
        "            if self.df[col].dtype in ['int64', 'float64']:\n",
        "                # Fill numerical columns with median\n",
        "                self.df[col] = self.df[col].fillna(self.df[col].median())\n",
        "            else:\n",
        "                # Fill categorical columns with 'Unknown'\n",
        "                self.df[col] = self.df[col].fillna('Unknown')\n",
        "\n",
        "        # Handle outliers by clipping to 1st-99th percentiles\n",
        "        numerical_cols = self.df.select_dtypes(include=[np.number]).columns\n",
        "        for col in numerical_cols:\n",
        "            if col != 'is_healthy':  # Don't clip the target\n",
        "                lower_bound = self.df[col].quantile(0.01)\n",
        "                upper_bound = self.df[col].quantile(0.99)\n",
        "                self.df[col] = self.df[col].clip(lower_bound, upper_bound)\n",
        "\n",
        "        print(\"Data cleaning completed!\")\n",
        "        return self.df\n",
        "\n",
        "    def visualize_data(self):\n",
        "        \"\"\"Create comprehensive visualizations\"\"\"\n",
        "        plt.style.use('default')\n",
        "\n",
        "        # 1. Target distribution\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle('Healthy Eating Dataset Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Target distribution\n",
        "        self.df['is_healthy'].value_counts().plot(kind='pie', ax=axes[0, 0], autopct='%1.1f%%')\n",
        "        axes[0, 0].set_title('Healthy vs Unhealthy Distribution')\n",
        "\n",
        "        # Calories distribution\n",
        "        self.df.boxplot(column='calories_per_100g', by='is_healthy', ax=axes[0, 1])\n",
        "        axes[0, 1].set_title('Calories by Health Status')\n",
        "\n",
        "        # Sugar distribution\n",
        "        self.df.boxplot(column='sugar_per_100g', by='is_healthy', ax=axes[0, 2])\n",
        "        axes[0, 2].set_title('Sugar by Health Status')\n",
        "\n",
        "        # Protein distribution\n",
        "        self.df.boxplot(column='protein_per_100g', by='is_healthy', ax=axes[1, 0])\n",
        "        axes[1, 0].set_title('Protein by Health Status')\n",
        "\n",
        "        # Fiber distribution\n",
        "        self.df.boxplot(column='fiber_per_100g', by='is_healthy', ax=axes[1, 1])\n",
        "        axes[1, 1].set_title('Fiber by Health Status')\n",
        "\n",
        "        # Sodium distribution\n",
        "        self.df.boxplot(column='sodium_per_100g', by='is_healthy', ax=axes[1, 2])\n",
        "        axes[1, 2].set_title('Sodium by Health Status')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('healthy_eating_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # Correlation heatmap\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
        "        correlation_matrix = self.df[numeric_cols].corr()\n",
        "        sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0,\n",
        "                   square=True, fmt='.2f')\n",
        "        plt.title('Feature Correlation Matrix')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('correlation_matrix_healthy.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Preprocess data for deep learning model\"\"\"\n",
        "        print(\"Preprocessing data...\")\n",
        "\n",
        "        # ----------------- 1) SAFE features that DON'T leak the target -----------------\n",
        "        feature_cols = [\n",
        "            # Base nutrients (NOT used to define target)\n",
        "            'protein_per_100g', 'carbs_per_100g', 'fat_per_100g', 'fiber_per_100g',\n",
        "\n",
        "            # SAFE nutrient densities (only non-leaking)\n",
        "            'protein_density', 'fiber_density',\n",
        "\n",
        "            # SAFE nutrient ratios (only non-leaking nutrients)\n",
        "            'protein_to_fat_ratio', 'protein_to_carb_ratio', 'fiber_to_carb_ratio',\n",
        "            'carb_fiber_ratio', 'fat_to_carb_ratio',\n",
        "\n",
        "            # Macronutrient percentages (SAFE - relative proportions)\n",
        "            'protein_pct', 'carb_pct', 'fat_pct',\n",
        "\n",
        "            # SAFE quality indicators\n",
        "            'nutrient_density_score', 'protein_fiber_ratio',\n",
        "\n",
        "            # SAFE interaction features\n",
        "            'protein_fiber_product', 'protein_carb_product',\n",
        "        ]\n",
        "\n",
        "        # ----------------- 2) BAN: ALL features that directly or indirectly leak -----------------\n",
        "        BAN = {\n",
        "            # Direct threshold features\n",
        "            'calories_per_100g',        # Used in target definition\n",
        "            'saturated_fat_per_100g',   # Used in target definition\n",
        "            'sugar_per_100g',           # Used in target definition\n",
        "            'sodium_per_100g',          # Used in target definition\n",
        "\n",
        "            # Indirect leakage through ratios/densities\n",
        "            'sugar_density',            # sugar/calories (leaks sugar)\n",
        "            'sodium_density',           # sodium/calories (leaks sodium)\n",
        "            'sat_fat_ratio',            # sat_fat/fat (leaks sat_fat)\n",
        "            'empty_calorie_ratio',      # sugar/calories (same as sugar_density)\n",
        "            'sodium_to_protein_ratio',  # sodium/protein (leaks sodium)\n",
        "            'sugar_fat_product',        # sugar*fat (leaks sugar)\n",
        "\n",
        "            # Derived features based on leaking nutrients\n",
        "            'energy_density',           # == calories_per_100g\n",
        "            'has_added_sugar',          # Based on sugar threshold\n",
        "            'is_ultra_processed',       # Based on calorie threshold\n",
        "\n",
        "            # The target itself\n",
        "            'is_healthy',\n",
        "        }\n",
        "\n",
        "        # ----------------- 3) Add categorical features -----------------\n",
        "        categorical_prefixes = ['cuisine_', 'type_', 'meal_category_', 'ingredients_']\n",
        "        for prefix in categorical_prefixes:\n",
        "            matching_cols = [col for col in self.df.columns if col.startswith(prefix)]\n",
        "            feature_cols.extend(matching_cols)\n",
        "\n",
        "        # ----------------- 4) Filter and validate -----------------\n",
        "        # Keep only existing columns\n",
        "        feature_cols = [c for c in feature_cols if c in self.df.columns]\n",
        "        # Remove any banned features\n",
        "        feature_cols = [c for c in feature_cols if c not in BAN]\n",
        "\n",
        "        # Save for later use\n",
        "        self.feature_columns = feature_cols\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"FEATURE SELECTION SUMMARY\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Total features selected: {len(self.feature_columns)}\")\n",
        "        print(f\"\\nAll features being used:\")\n",
        "        for i, feat in enumerate(self.feature_columns, 1):\n",
        "            print(f\"  {i}. {feat}\")\n",
        "\n",
        "        # Check for any banned features that snuck through\n",
        "        banned_in_use = [f for f in self.feature_columns if f in BAN]\n",
        "        if banned_in_use:\n",
        "            print(f\"\\n⚠️  WARNING: BANNED FEATURES DETECTED IN USE: {banned_in_use}\")\n",
        "            raise ValueError(f\"Banned features found in feature list: {banned_in_use}\")\n",
        "\n",
        "        # ----------------- 5) Build X, y with final checks -----------------\n",
        "        X = self.df[self.feature_columns].copy()\n",
        "        y = self.df['is_healthy'].copy()\n",
        "\n",
        "        # ----------------- 6) DATA QUALITY CHECK -----------------\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"DATA QUALITY CHECK\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Check for constant/zero-variance features\n",
        "        constant_features = []\n",
        "        for col in X.columns:\n",
        "            if X[col].nunique() <= 1:\n",
        "                constant_features.append(col)\n",
        "                print(f\"⚠️  WARNING: {col} has constant values (variance=0)!\")\n",
        "\n",
        "        if constant_features:\n",
        "            print(f\"\\n🚨 CRITICAL ERROR: {len(constant_features)} features have no variance!\")\n",
        "            print(\"This means all values are the same (likely all zeros).\")\n",
        "            print(\"The dataset or preprocessing has a serious problem!\")\n",
        "            print(\"\\nConstant features detected:\")\n",
        "            for feat in constant_features:\n",
        "                unique_vals = X[feat].unique()\n",
        "                print(f\"  - {feat}: only has value(s) {unique_vals}\")\n",
        "\n",
        "        # Check basic statistics\n",
        "        print(f\"\\nFeature Statistics:\")\n",
        "        print(f\"Total features: {len(X.columns)}\")\n",
        "        print(f\"Features with variance: {len([c for c in X.columns if X[c].nunique() > 1])}\")\n",
        "        print(f\"Features with constant values: {len(constant_features)}\")\n",
        "\n",
        "        # Show sample of feature values\n",
        "        print(f\"\\nSample feature values (first 5 rows):\")\n",
        "        print(X.head().to_string())\n",
        "\n",
        "        # ----------------- 7) LEAK DETECTION: Check correlations with target -----------------\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"CORRELATION ANALYSIS WITH TARGET\")\n",
        "        print(f\"{'='*80}\")\n",
        "        correlations = []\n",
        "        for col in self.feature_columns:\n",
        "            if X[col].dtype in ['int64', 'float64']:\n",
        "                if X[col].nunique() > 1:  # Only compute if not constant\n",
        "                    corr = abs(X[col].corr(y))\n",
        "                    if not pd.isna(corr):\n",
        "                        correlations.append((col, corr))\n",
        "                else:\n",
        "                    correlations.append((col, 0.0))\n",
        "\n",
        "        # Sort by correlation\n",
        "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        print(\"\\nTop 10 features most correlated with target:\")\n",
        "        for i, (feat, corr) in enumerate(correlations[:10], 1):\n",
        "            if pd.isna(corr) or corr == 0.0:\n",
        "                print(f\"  {i}. {feat}: NO VARIANCE (constant values)\")\n",
        "            else:\n",
        "                warning = \" ⚠️  SUSPICIOUSLY HIGH!\" if corr > 0.9 else \"\"\n",
        "                print(f\"  {i}. {feat}: {corr:.4f}{warning}\")\n",
        "\n",
        "        # Check for extremely high correlations (potential leakage)\n",
        "        high_corr_features = [feat for feat, corr in correlations if not pd.isna(corr) and corr > 0.9]\n",
        "        if high_corr_features:\n",
        "            print(f\"\\n⚠️  WARNING: Features with correlation > 0.9 detected!\")\n",
        "            print(f\"These features may be leaking target information:\")\n",
        "            for feat in high_corr_features:\n",
        "                corr_val = next(c for f, c in correlations if f == feat)\n",
        "                print(f\"  - {feat}: {corr_val:.4f}\")\n",
        "            print(\"\\nConsider removing these features or investigating the data!\")\n",
        "\n",
        "        # Critical check: if most features are constant, stop\n",
        "        if len(constant_features) > len(X.columns) * 0.5:\n",
        "            raise ValueError(f\"CRITICAL: More than 50% of features have constant values! \"\n",
        "                           f\"Dataset preprocessing has failed. Check the normalize_units() \"\n",
        "                           f\"and engineer_features() methods.\")\n",
        "\n",
        "        # Final validation\n",
        "        if X.isnull().any().any():\n",
        "            print(\"Warning: Features contain NaN values, filling with median...\")\n",
        "            X = X.fillna(X.median())\n",
        "\n",
        "        if y.isnull().any():\n",
        "            print(\"Warning: Target contains NaN values, filling with mode...\")\n",
        "            y = y.fillna(y.mode()[0])\n",
        "\n",
        "        print(f\"Feature matrix shape: {X.shape}\")\n",
        "        print(f\"Target shape: {y.shape}\")\n",
        "        print(f\"Features used (after BAN): {len(self.feature_columns)}\")\n",
        "        # Optional: print a few banned features found in df (for sanity)\n",
        "        banned_present = [c for c in BAN if c in self.df.columns]\n",
        "        if banned_present:\n",
        "            print(f\"Banned features detected (excluded): {banned_present}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    def split_and_scale_data(self, X, y, use_smote=True):\n",
        "        \"\"\"Split data into train/val/test and scale features\"\"\"\n",
        "        print(\"Splitting and scaling data...\")\n",
        "\n",
        "        # Stratified split: 70% train, 15% val, 15% test\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, y, test_size=0.15, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 * 0.85 ≈ 0.15\n",
        "        )\n",
        "\n",
        "        print(f\"Original training set: {X_train.shape}\")\n",
        "        print(f\"Original class distribution - Train: {np.bincount(y_train)}\")\n",
        "\n",
        "        # Apply SMOTE to training data only (not validation or test)\n",
        "        # WARNING: SMOTE might be causing unrealistic results by creating too-perfect synthetic samples\n",
        "        if use_smote and SMOTE_AVAILABLE:\n",
        "            print(\"\\n⚠️  WARNING: SMOTE is enabled but might cause overfitting!\")\n",
        "            print(\"If you're getting unrealistically high accuracy (>95%), try disabling SMOTE.\")\n",
        "            print(\"To disable: change use_smote=False in split_and_scale_data() call\\n\")\n",
        "\n",
        "            print(\"Applying SMOTE to balance training data...\")\n",
        "            smote = SMOTE(random_state=42, k_neighbors=5)\n",
        "            try:\n",
        "                X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "                print(f\"After SMOTE - Training set: {X_train.shape}\")\n",
        "                print(f\"After SMOTE - Class distribution: {np.bincount(y_train)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"SMOTE failed: {e}. Continuing without SMOTE.\")\n",
        "        else:\n",
        "            print(\"\\nSMOTE is disabled - using original imbalanced data\")\n",
        "\n",
        "        # Scale features AFTER SMOTE\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_val_scaled = self.scaler.transform(X_val)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        print(f\"\\nFinal training set: {X_train_scaled.shape}\")\n",
        "        print(f\"Validation set: {X_val_scaled.shape}\")\n",
        "        print(f\"Test set: {X_test_scaled.shape}\")\n",
        "        print(f\"Final class distribution - Train: {np.bincount(y_train)}\")\n",
        "        print(f\"Class distribution - Val: {np.bincount(y_val)}\")\n",
        "        print(f\"Class distribution - Test: {np.bincount(y_test)}\")\n",
        "\n",
        "        return (X_train_scaled, X_val_scaled, X_test_scaled,\n",
        "                y_train, y_val, y_test)\n",
        "\n",
        "    def build_model(self, input_dim):\n",
        "        \"\"\"Build deep learning model architecture\"\"\"\n",
        "        print(\"Building healthy eating classification model...\")\n",
        "\n",
        "        # Calculate class weights for imbalance\n",
        "        class_counts = np.bincount(self.df['is_healthy'])\n",
        "        total_samples = class_counts.sum()\n",
        "        class_weights = {\n",
        "            0: total_samples / (2 * class_counts[0]),  # Unhealthy\n",
        "            1: total_samples / (2 * class_counts[1])  # Healthy\n",
        "        }\n",
        "        print(f\"Class weights: {class_weights}\")\n",
        "        print(f\"Class distribution: Unhealthy={class_counts[0]}, Healthy={class_counts[1]}\")\n",
        "\n",
        "        # Balanced architecture - deep enough but not overfit\n",
        "        model = keras.Sequential([\n",
        "            # Input layer with batch normalization\n",
        "            layers.Dense(64, input_shape=(input_dim,)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.Dropout(0.4),\n",
        "\n",
        "            # Second hidden layer\n",
        "            layers.Dense(32, kernel_regularizer=regularizers.l2(1e-3)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.Dropout(0.4),\n",
        "\n",
        "            # Third hidden layer\n",
        "            layers.Dense(16, kernel_regularizer=regularizers.l2(1e-3)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.Dropout(0.3),\n",
        "\n",
        "            # Output layer\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        # Compile with adjusted learning rate\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=5e-4),  # Lower learning rate\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', keras.metrics.AUC(name='auc'),\n",
        "                    keras.metrics.Precision(name='precision'),\n",
        "                    keras.metrics.Recall(name='recall')]\n",
        "        )\n",
        "\n",
        "        print(\"Model Architecture:\")\n",
        "        model.summary()\n",
        "\n",
        "        return model, class_weights\n",
        "\n",
        "    def train_model(self, model, X_train, y_train, X_val, y_val, class_weights):\n",
        "        \"\"\"Train the deep learning model\"\"\"\n",
        "        print(\"Training model...\")\n",
        "\n",
        "        # Define callbacks with more aggressive settings\n",
        "        callbacks = [\n",
        "            keras.callbacks.EarlyStopping(\n",
        "                monitor='val_auc',\n",
        "                patience=20,  # Increased patience\n",
        "                restore_best_weights=True,\n",
        "                mode='max',\n",
        "                verbose=1\n",
        "            ),\n",
        "            keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=10,  # Increased patience\n",
        "                min_lr=1e-7,\n",
        "                verbose=1\n",
        "            ),\n",
        "            keras.callbacks.ModelCheckpoint(\n",
        "                'best_model_temp.h5',\n",
        "                monitor='val_auc',\n",
        "                save_best_only=True,\n",
        "                mode='max',\n",
        "                verbose=0\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Train the model with adjusted batch size\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=150,  # More epochs\n",
        "            batch_size=16,  # Smaller batch size for better learning\n",
        "            class_weight=class_weights,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def evaluate_model(self, model, X_test, y_test, threshold=None):\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "        print(\"Evaluating model...\")\n",
        "\n",
        "        # Get predictions\n",
        "        y_pred_proba = model.predict(X_test).flatten()\n",
        "\n",
        "        # Use optimal threshold if not provided\n",
        "        if threshold is None:\n",
        "            precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "            optimal_idx = np.argmax(f1_scores)\n",
        "            threshold = thresholds[optimal_idx]\n",
        "            print(f\"Optimal threshold: {threshold:.4f}\")\n",
        "\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "        # Calculate metrics\n",
        "        test_accuracy = accuracy_score(y_test, y_pred)            # Accuracy at your threshold\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)   # AUC from probabilities\n",
        "        test_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Additional metrics with macro and weighted averages\n",
        "        precision_macro = precision_score(y_test, y_pred, average='macro')\n",
        "        precision_weighted = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall_macro = recall_score(y_test, y_pred, average='macro')\n",
        "        recall_weighted = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        print(f\"\\nTest Results:\")\n",
        "        print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "        print(f\"AUC: {test_auc:.4f}\")\n",
        "        print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
        "        print(f\"Precision (Weighted): {precision_weighted:.4f}\")\n",
        "        print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
        "        print(f\"Recall (Weighted): {recall_weighted:.4f}\")\n",
        "        print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
        "        print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")\n",
        "\n",
        "        # Classification report\n",
        "        print(\"\\nDetailed Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred, target_names=['Unhealthy', 'Healthy']))\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=['Unhealthy', 'Healthy'],\n",
        "                   yticklabels=['Unhealthy', 'Healthy'])\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('confusion_matrix_healthy.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # Create metrics summary plot\n",
        "        self.plot_metrics_summary(test_accuracy, precision_macro, recall_macro, f1_macro)\n",
        "\n",
        "        # Create comprehensive metrics table\n",
        "        self.create_metrics_table(test_accuracy, precision_macro, recall_macro, f1_macro)\n",
        "\n",
        "        return y_pred, y_pred_proba, threshold\n",
        "\n",
        "    def plot_metrics_summary(self, accuracy, precision, recall, f1):\n",
        "        \"\"\"Plot metrics summary bar chart\"\"\"\n",
        "        metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "        values = [accuracy, precision, recall, f1]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(metrics, values, color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
        "        plt.title('Model Performance Metrics Summary', fontsize=14, fontweight='bold')\n",
        "        plt.ylabel('Score', fontsize=12)\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar, value in zip(bars, values):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('metrics_summary_healthy.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def create_metrics_table(self, accuracy, precision, recall, f1):\n",
        "        \"\"\"Create comprehensive metrics table\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE MODEL PERFORMANCE METRICS TABLE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Create metrics DataFrame\n",
        "        metrics_data = {\n",
        "            'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "            'Score': [f\"{accuracy:.4f}\", f\"{precision:.4f}\", f\"{recall:.4f}\", f\"{f1:.4f}\"]\n",
        "        }\n",
        "\n",
        "        metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "        print(\"\\nModel Performance Metrics:\")\n",
        "        print(metrics_df.to_string(index=False))\n",
        "\n",
        "        # Create visual table\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.axis('tight')\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Create table\n",
        "        table_data = [\n",
        "            ['Accuracy', f\"{accuracy:.4f}\"],\n",
        "            ['Precision', f\"{precision:.4f}\"],\n",
        "            ['Recall', f\"{recall:.4f}\"],\n",
        "            ['F1-Score', f\"{f1:.4f}\"]\n",
        "        ]\n",
        "\n",
        "        headers = ['Metric', 'Score']\n",
        "        table = ax.table(cellText=table_data, colLabels=headers,\n",
        "                        cellLoc='center', loc='center')\n",
        "\n",
        "        # Style the table\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(12)\n",
        "        table.scale(1.2, 2)\n",
        "\n",
        "        # Color code the rows\n",
        "        for i in range(len(table_data) + 1):\n",
        "            for j in range(len(headers)):\n",
        "                cell = table[(i, j)]\n",
        "                if i == 0:  # Header row\n",
        "                    cell.set_facecolor('#4CAF50')\n",
        "                    cell.set_text_props(weight='bold', color='white')\n",
        "                else:  # Data rows\n",
        "                    cell.set_facecolor('#F5F5F5')\n",
        "\n",
        "        plt.title('Model Performance Metrics Table', fontsize=16, fontweight='bold', pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('metrics_table_healthy.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # Save metrics to CSV\n",
        "        metrics_df.to_csv('model_metrics_healthy.csv', index=False)\n",
        "        print(f\"\\nMetrics table saved to 'model_metrics_healthy.csv'\")\n",
        "\n",
        "        return metrics_df\n",
        "\n",
        "    def _pick_threshold_on_validation(self, y_val, val_proba, mode=\"macro_f1\"):\n",
        "        \"\"\"\n",
        "        Choose a probability threshold using the validation set that optimizes\n",
        "        a metric considering BOTH classes. Supported modes: 'macro_f1', 'balanced_acc'.\n",
        "        \"\"\"\n",
        "        # Candidate thresholds: all unique probs plus 0 and 1\n",
        "        thr_candidates = np.r_[0.0, np.sort(np.unique(val_proba)), 1.0]\n",
        "\n",
        "        best_thr, best_score = 0.5, -1.0\n",
        "        for t in thr_candidates:\n",
        "            y_hat = (val_proba >= t).astype(int)\n",
        "            if mode == \"macro_f1\":\n",
        "                score = f1_score(y_val, y_hat, average=\"macro\", zero_division=0)\n",
        "            elif mode == \"balanced_acc\":\n",
        "                # balanced accuracy = avg(sensitivity, specificity)\n",
        "                tn, fp, fn, tp = confusion_matrix(y_val, y_hat).ravel()\n",
        "                tpr = tp / (tp + fn + 1e-12)\n",
        "                tnr = tn / (tn + fp + 1e-12)\n",
        "                score = 0.5 * (tpr + tnr)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported mode for threshold picking.\")\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score, best_thr = score, t\n",
        "\n",
        "        print(f\"[Threshold search] mode={mode} best={best_score:.4f} @ thr={best_thr:.4f}\")\n",
        "        return best_thr\n",
        "\n",
        "\n",
        "    def create_validation_test_comparison(self, model, X_val, y_val, X_test, y_test, threshold):\n",
        "        \"\"\"Create comparison between validation and test performance\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"VALIDATION vs TEST SET PERFORMANCE COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Get predictions for both sets\n",
        "        y_val_pred_proba = model.predict(X_val).flatten()\n",
        "        y_test_pred_proba = model.predict(X_test).flatten()\n",
        "\n",
        "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
        "        y_test_pred = (y_test_pred_proba >= threshold).astype(int)\n",
        "\n",
        "\n",
        "        # Calculate metrics for validation set\n",
        "        val_accuracy = model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "        val_precision = precision_score(y_val, y_val_pred, average='macro')\n",
        "        val_recall = recall_score(y_val, y_val_pred, average='macro')\n",
        "        val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
        "\n",
        "        # Calculate metrics for test set\n",
        "        test_accuracy = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "        test_precision = precision_score(y_test, y_test_pred, average='macro')\n",
        "        test_recall = recall_score(y_test, y_test_pred, average='macro')\n",
        "        test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "        # Create comparison DataFrame\n",
        "        comparison_data = {\n",
        "            'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "            'Validation': [val_accuracy, val_precision, val_recall, val_f1],\n",
        "            'Test': [test_accuracy, test_precision, test_recall, test_f1],\n",
        "            'Difference': [\n",
        "                test_accuracy - val_accuracy,\n",
        "                test_precision - val_precision,\n",
        "                test_recall - val_recall,\n",
        "                test_f1 - val_f1\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        comparison_df['Validation'] = comparison_df['Validation'].round(4)\n",
        "        comparison_df['Test'] = comparison_df['Test'].round(4)\n",
        "        comparison_df['Difference'] = comparison_df['Difference'].round(4)\n",
        "\n",
        "        print(\"\\nValidation vs Test Performance Comparison:\")\n",
        "        print(comparison_df.to_string(index=False))\n",
        "\n",
        "        # Create visual comparison\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        x = np.arange(len(comparison_df))\n",
        "        width = 0.35\n",
        "\n",
        "        bars1 = ax.bar(x - width/2, comparison_df['Validation'], width,\n",
        "                      label='Validation', color='skyblue', alpha=0.8)\n",
        "        bars2 = ax.bar(x + width/2, comparison_df['Test'], width,\n",
        "                      label='Test', color='lightcoral', alpha=0.8)\n",
        "\n",
        "        ax.set_xlabel('Metrics', fontsize=12)\n",
        "        ax.set_ylabel('Score', fontsize=12)\n",
        "        ax.set_title('Validation vs Test Set Performance Comparison', fontsize=14, fontweight='bold')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(comparison_df['Metric'])\n",
        "        ax.legend()\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bars in [bars1, bars2]:\n",
        "            for bar in bars:\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                       f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('validation_test_comparison_healthy.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # Save comparison to CSV\n",
        "        comparison_df.to_csv('validation_test_comparison_healthy.csv', index=False)\n",
        "        print(f\"\\nComparison table saved to 'validation_test_comparison_healthy.csv'\")\n",
        "\n",
        "        return comparison_df\n",
        "\n",
        "    def plot_training_history(self, history):\n",
        "        \"\"\"Plot training history\"\"\"\n",
        "        hist = history.history\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "        # Accuracy\n",
        "        axes[0].plot(hist.get('accuracy', []), label='Training Accuracy')\n",
        "        axes[0].plot(hist.get('val_accuracy', []), label='Validation Accuracy')\n",
        "        axes[0].set_title('Model Accuracy')\n",
        "        axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Accuracy')\n",
        "        axes[0].legend(); axes[0].grid(True)\n",
        "\n",
        "        # Loss\n",
        "        axes[1].plot(hist.get('loss', []), label='Training Loss')\n",
        "        axes[1].plot(hist.get('val_loss', []), label='Validation Loss')\n",
        "        axes[1].set_title('Model Loss')\n",
        "        axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Loss')\n",
        "        axes[1].legend(); axes[1].grid(True)\n",
        "\n",
        "        # AUC (only if present)\n",
        "        auc_train = hist.get('auc', None)\n",
        "        auc_val   = hist.get('val_auc', None)\n",
        "        if auc_train is not None or auc_val is not None:\n",
        "            axes[2].plot(auc_train or [], label='Training AUC')\n",
        "            axes[2].plot(auc_val or [], label='Validation AUC')\n",
        "            axes[2].set_title('Model AUC')\n",
        "            axes[2].set_xlabel('Epoch'); axes[2].set_ylabel('AUC')\n",
        "            axes[2].legend(); axes[2].grid(True)\n",
        "        else:\n",
        "            axes[2].set_visible(False)  # hide third panel if no AUC logged\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_history_healthy.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def analyze_feature_importance(self, model, X_test, y_test):\n",
        "        \"\"\"Analyze feature importance using permutation importance\"\"\"\n",
        "        print(\"Analyzing feature importance...\")\n",
        "\n",
        "        def analyze_feature_importance(self, model, X_test, y_test):\n",
        "          \"\"\"Analyze feature importance using permutation importance (binary classifier).\"\"\"\n",
        "          print(\"Analyzing feature importance...\")\n",
        "\n",
        "\n",
        "\n",
        "          # --- Wrapper so the Keras model looks like an sklearn estimator ---\n",
        "          class KerasPIWrapper:\n",
        "              def __init__(self, trained_model):\n",
        "                  self.model = trained_model\n",
        "              def fit(self, X, y):\n",
        "                  # No-op; required by sklearn API\n",
        "                  return self\n",
        "              def predict(self, X):\n",
        "                  # Convert predicted probabilities to class labels (0/1)\n",
        "                  proba = self.model.predict(X, verbose=0).flatten()\n",
        "                  return (proba >= 0.5).astype(int)\n",
        "              def score(self, X, y):\n",
        "                  # Accuracy score used by permutation_importance when scoring=\"accuracy\"\n",
        "                  return accuracy_score(y, self.predict(X))\n",
        "\n",
        "          est = KerasPIWrapper(model)\n",
        "\n",
        "          # Run permutation importance on the (already scaled) test set\n",
        "          perm = permutation_importance(\n",
        "              estimator=est,\n",
        "              X=X_test,\n",
        "              y=y_test,\n",
        "              n_repeats=10,\n",
        "              random_state=42,\n",
        "              scoring=\"accuracy\",\n",
        "              n_jobs=-1\n",
        "          )\n",
        "\n",
        "          # Build results DataFrame\n",
        "          # Fallback in case feature names are missing/mismatched\n",
        "          if not self.feature_columns or len(self.feature_columns) != X_test.shape[1]:\n",
        "              feature_names = [f\"feature_{i}\" for i in range(X_test.shape[1])]\n",
        "          else:\n",
        "              feature_names = list(self.feature_columns)\n",
        "\n",
        "          feature_importance_df = (\n",
        "              pd.DataFrame({\n",
        "                  \"feature\": feature_names,\n",
        "                  \"importance\": perm.importances_mean,\n",
        "                  \"std\": perm.importances_std\n",
        "              })\n",
        "              .sort_values(\"importance\", ascending=True)\n",
        "              .reset_index(drop=True)\n",
        "          )\n",
        "\n",
        "          print(\"\\nTop 10 Most Important Features:\")\n",
        "          print(feature_importance_df.tail(10).to_string(index=False))\n",
        "\n",
        "          # ----- Plot: Top 15 (or fewer if not enough features) -----\n",
        "          top_k = min(15, len(feature_importance_df))\n",
        "          top_features = feature_importance_df.tail(top_k)\n",
        "\n",
        "          plt.figure(figsize=(12, 8))\n",
        "          bars = plt.barh(\n",
        "              range(len(top_features)),\n",
        "              top_features[\"importance\"],\n",
        "              xerr=top_features[\"std\"],\n",
        "              capsize=5,\n",
        "              color='skyblue',\n",
        "              alpha=0.7\n",
        "          )\n",
        "          plt.yticks(range(len(top_features)), top_features[\"feature\"])\n",
        "          plt.xlabel(\"Feature Importance (mean decrease in accuracy)\")\n",
        "          plt.title(f\"Top {top_k} Most Important Features for Healthy Eating Prediction\")\n",
        "          plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "          # Value labels\n",
        "          for bar, importance in zip(bars, top_features[\"importance\"]):\n",
        "              plt.text(\n",
        "                  importance + (0.001 if np.isfinite(importance) else 0),\n",
        "                  bar.get_y() + bar.get_height()/2,\n",
        "                  f\"{importance:.3f}\",\n",
        "                  va=\"center\",\n",
        "                  fontsize=9\n",
        "              )\n",
        "\n",
        "          plt.tight_layout()\n",
        "          plt.savefig(\"feature_importance_healthy.png\", dpi=300, bbox_inches=\"tight\")\n",
        "          plt.show()\n",
        "\n",
        "          return feature_importance_df\n",
        "\n",
        "    def plot_roc_pr_curves(self, y_test, y_pred_proba):\n",
        "        \"\"\"Plot ROC and Precision-Recall curves\"\"\"\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # ROC Curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "        ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        ax1.set_xlim([0.0, 1.0])\n",
        "        ax1.set_ylim([0.0, 1.05])\n",
        "        ax1.set_xlabel('False Positive Rate')\n",
        "        ax1.set_ylabel('True Positive Rate')\n",
        "        ax1.set_title('ROC Curve')\n",
        "        ax1.legend(loc=\"lower right\")\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Precision-Recall Curve\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "        pr_auc = auc(recall, precision)\n",
        "\n",
        "        ax2.plot(recall, precision, color='darkorange', lw=2, label=f'PR curve (AUC = {pr_auc:.3f})')\n",
        "        ax2.set_xlim([0.0, 1.0])\n",
        "        ax2.set_ylim([0.0, 1.05])\n",
        "        ax2.set_xlabel('Recall')\n",
        "        ax2.set_ylabel('Precision')\n",
        "        ax2.set_title('Precision-Recall Curve')\n",
        "        ax2.legend(loc=\"lower left\")\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('roc_pr_curves_healthy.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        return roc_auc, pr_auc\n",
        "\n",
        "    def run_complete_analysis(self, file_path):\n",
        "        \"\"\"Run the complete healthy eating analysis pipeline\"\"\"\n",
        "        print(\"=\"*60)\n",
        "        print(\"HEALTHY EATING DEEP LEARNING ANALYSIS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        try:\n",
        "            # Load and explore data\n",
        "            self.load_and_explore_data(file_path)\n",
        "\n",
        "            # Normalize units\n",
        "            self.normalize_units()\n",
        "\n",
        "            # Engineer features\n",
        "            self.engineer_features()\n",
        "\n",
        "            # Create healthy target\n",
        "            self.create_healthy_target()\n",
        "\n",
        "            # Clean data\n",
        "            self.clean_data()\n",
        "\n",
        "            # Visualize data\n",
        "            self.visualize_data()\n",
        "\n",
        "            # Preprocess data\n",
        "            X, y = self.preprocess_data()\n",
        "\n",
        "            # Split and scale data\n",
        "            # SMOTE enabled to handle severe class imbalance (9% healthy vs 91% unhealthy)\n",
        "            X_train, X_val, X_test, y_train, y_val, y_test = self.split_and_scale_data(X, y, use_smote=True)\n",
        "\n",
        "            # Build model\n",
        "            model, class_weights = self.build_model(X_train.shape[1])\n",
        "\n",
        "            # Train model\n",
        "            history = self.train_model(model, X_train, y_train, X_val, y_val, class_weights)\n",
        "\n",
        "            # Plot training history\n",
        "            self.plot_training_history(history)\n",
        "\n",
        "            # ---------- pick threshold on VALIDATION (no test leakage) ----------\n",
        "            val_proba = model.predict(X_val).flatten()\n",
        "            # Choose ONE of the two modes below:\n",
        "            val_opt_threshold = self._pick_threshold_on_validation(y_val, val_proba, mode=\"macro_f1\")\n",
        "            # val_opt_threshold = self._pick_threshold_on_validation(y_val, val_proba, mode=\"balanced_acc\")\n",
        "            # --------------------------------------------------------------------\n",
        "\n",
        "            # Evaluate on TEST using the validation-derived threshold\n",
        "            y_pred, y_pred_proba, _ = self.evaluate_model(\n",
        "                model, X_test, y_test, threshold=val_opt_threshold\n",
        "            )\n",
        "\n",
        "            # Plot ROC and PR curves\n",
        "            roc_auc, pr_auc = self.plot_roc_pr_curves(y_test, y_pred_proba)\n",
        "\n",
        "            # Analyze feature importance\n",
        "            feature_importance = self.analyze_feature_importance(model, X_test, y_test)\n",
        "\n",
        "            # Create validation vs test comparison (using the validation-derived threshold)\n",
        "            self.create_validation_test_comparison(\n",
        "                model, X_val, y_val, X_test, y_test, threshold=val_opt_threshold)\n",
        "\n",
        "            # Save model\n",
        "            model.save('healthy_eating_model.h5')\n",
        "            print(\"\\nModel saved as 'healthy_eating_model.h5'\")\n",
        "\n",
        "            return {\n",
        "                'model': model,\n",
        "                'history': history,\n",
        "                'feature_importance': feature_importance,\n",
        "                'predictions': y_pred,\n",
        "                'probabilities': y_pred_proba,\n",
        "                'threshold': val_opt_threshold,\n",
        "                'roc_auc': roc_auc,\n",
        "                'pr_auc': pr_auc\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError during analysis: {str(e)}\")\n",
        "            print(\"This might be due to:\")\n",
        "            print(\"1. Missing required columns in the dataset\")\n",
        "            print(\"2. Incompatible data types\")\n",
        "            print(\"3. Missing values in critical columns\")\n",
        "            raise e\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the healthy eating analysis\"\"\"\n",
        "    # Initialize the classifier\n",
        "    classifier = HealthyEatingClassifier()\n",
        "\n",
        "    # Run complete analysis\n",
        "    file_path = \"/content/sample_data/healthy_eating_dataset.csv\"  # Update this path\n",
        "\n",
        "    try:\n",
        "        results = classifier.run_complete_analysis(file_path)\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ANALYSIS COMPLETE!\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"Generated files:\")\n",
        "        print(\"- healthy_eating_analysis.png\")\n",
        "        print(\"- correlation_matrix_healthy.png\")\n",
        "        print(\"- confusion_matrix_healthy.png\")\n",
        "        print(\"- training_history_healthy.png\")\n",
        "        print(\"- feature_importance_healthy.png\")\n",
        "        print(\"- roc_pr_curves_healthy.png\")\n",
        "        print(\"- metrics_summary_healthy.png\")\n",
        "        print(\"- metrics_table_healthy.png\")\n",
        "        print(\"- validation_test_comparison_healthy.png\")\n",
        "        print(\"- model_metrics_healthy.csv\")\n",
        "        print(\"- validation_test_comparison_healthy.csv\")\n",
        "        print(\"- healthy_eating_model.h5\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Could not find the dataset file at '{file_path}'\")\n",
        "        print(\"Please update the file_path variable with the correct path to your dataset.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during analysis: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}